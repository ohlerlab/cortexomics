# the qc step at the moment assumes that the data is single ended
#
shell.executable("bash")
shell.prefix("set -e  pipefail;")
# user set parameter
TMPDIR = '../tmp'
SCRIPTDIR = '../git/rna_seq/scripts'

# #reference genome
REF_orig = '/fast/projects/cubit/0.12.0/static_data/annotation/GENCODE/M12/GRCm38/GRCm38.p5.genome.chr_scaff.fa'

# import os
# def filebase(file): return()


# # used by star
# STARINDEX = "/fast/projects/cubit/0.12.0/static_data/precomputed/STAR/2.4.1d/GENCODE/M12/GRCm38/p5.chr_scaff/50/"
# # used by 
# GTF_orig = '/fast/projects/cubit/0.12.0/static_data/annotation/GENCODE/M12/GRCm38/gencode.vM12.annotation.gtf'
# GTF_cdsfilt = 'static_local/gencode.vM12.annotation_cdsfilt.gtf'
# CDSGTF = 'static_local/gencode.vM12.annotation.cds.gtf'

# # used by infer_experiment
# BED = 'static_local/gencode.vM12.annotation.bed'
# GFF = '/fast/projects/cubit/0.12.0/static_data/annotation/GENCODE/M12/GRCm38/gencode.vM12.annotation.gff3'

REF = 'my_'+os.path.splitext(os.path.split(REF_orig)[1])[0]+'.fa'


#STAR uses the rsem index
STARINDEX = 'rsemref'

# used by infer_experiment
GFF_orig = 'gencode.vM12.annotation.gff3'

ANNOBASE = 'my_'+os.path.splitext(os.path.split(GFF_orig)[1])[0]

GFF = ANNOBASE+'.gff3'
GFF_mod = ANNOBASE+'.mod.gff3'

BED = ANNOBASE+'.bed'

# used by 
GTF = ANNOBASE+'.gtf'
CDSGTF = ANNOBASE+'.cdsfilt.gtf'
#used to make indices
RNAFASTA = ANNOBASE+'.transcript.fa'
CDSFASTA = ANNOBASE+'.cds.fa'

# need to think on this.... we start with a genome and a gff3 file. We add the extra transcript to our gff3 file, (optionally eliminating all others) 
#then we create the transcript fasta file from our gff3 file, and the gtf file. Then, we use these to make salmon, and rsem/star indices

# htseq parameter
HTSEQ_MODE = 'union'


# used by qc
SeQC_GTF = 'gencode.vM12.chr_scaff.annotation.no_genes.protein_coding.rRNA.gtf'
SeQC_REF = REF


KINDEXCDS = 'kallistoindex/mouse_encode_m12_cds.kdx'
KINDEX    = 'kallistoindex/gencode.vM12.transcripts.kdx'
KMERSIZE  = 21
kallistobin = "~/bin/kallisto"


RSEMINDEXFOLD="rsemref"

ebp1_wrong_cds = "specific_seq_folder/pa2g4_CDSseq_with_wrongsplice.fa"
ebp1_wrong_mRNA="specific_seq_folder/pa2g4_mRNAseq_with_wrongsplice.fa"

SAMPLELINES = [line.strip().split(',') for line in open("sample_parameter.csv").readlines()]

#switch for testmode
if(config.get('test',0)): 
  print('\n\n--------testmode on -------------\n\n')
  SAMPLELINES = SAMPLELINES[0:2]  
  origSAMPLE = [ entry[SAMPLELINES[0].index('sample_id')] for entry in SAMPLELINES[1:]]
  SAMPLES = ['test']

else:
  SAMPLES = [ entry[SAMPLELINES[0].index('sample_id')] for entry in SAMPLELINES[1:]]

#get our info as dictionaries
def tab_to_dict(SAMPLELINES,valcol):
  valind = SAMPLELINES[0].index(valcol)
  vals   = [ entry[valind] for entry in SAMPLELINES[1:]]
  return dict(zip(SAMPLES,vals))

#sample - info dictionaries
LIBRARY_DICT          = tab_to_dict(SAMPLELINES,'library_layout')
READ_PATTERN_DICT     = tab_to_dict(SAMPLELINES,'read_pattern')
PROTOCOL_DICT         = tab_to_dict(SAMPLELINES, 'protocol')
FRAG_LENGTH_MEAN_DICT = tab_to_dict(SAMPLELINES, 'fragment_length_mean')
FRAG_LENGTH_SD_DICT   = tab_to_dict(SAMPLELINES, 'fragment_length_sd')
ASSAY_DICT            = tab_to_dict(SAMPLELINES, 'assay')

GTF_DICT              = {k: CDSGTF if 'ribo' in v else GTF for k, v in ASSAY_DICT.items()}
KINDEXDICT            = {k: KINDEXCDS if 'ribo' in v else KINDEX for k,v in ASSAY_DICT.items()}

print(READ_PATTERN_DICT)
#the group dict is structured differently, returns a list of samples
GROUP_DICT = tab_to_dict(SAMPLELINES,'group')
GROUP_SAMPLES = {}

for k, v in GROUP_DICT.items():
    GROUP_SAMPLES[v] = GROUP_SAMPLES.get(v, [])
    GROUP_SAMPLES[v].append(k)

GROUPS = list(GROUP_SAMPLES.keys())

#information on the strand of stuff
strands = ['pos','neg']
STRANDSYMS={strands[0]:'+',strands[1]:'-'}

#extensions for transcript and chromosome bigwigs
istransvals = ['.transcript','.chr']
#extensions used by STAR to denot the transcript/genomic bam
BEXTS={istransvals[0]:'.star_transcript',istransvals[1]:''}


print('Samples are: ',SAMPLES)
print('Groups are: ',GROUPS)


RIBO_TOTAL_DICT = dict(zip(
  list(filter(lambda x: 'ribo' in x,SAMPLES)),
  list(filter(lambda x: 'total' in x,SAMPLES))
))

GENEREGIONS = ['gene','cds','fputrs','tputrs']
# generegions = ['gene','cds','fputrs','tputrs','cds_tiles','fputr_tiles','tputr_tiles']

# TRNAs = ['gencode.vM12.tRNAs.gtf.gz']
TRNAs = ['tRNAs']
# print(expand("feature_counts/data/{sample}/{generegions}.done", sample = SAMPLES, generegions = generegions))

READRANGES = ['25_30','1_26','27_28','29_100','1_300']
READRANGENUM = [[25,30],[1,26],[27,28],[29,100],[1,300]]
READRANGEDICT = dict(zip(READRANGES,READRANGENUM))

rule all:
  input:
    expand("preprocessed_reads/{sample}/{sample}.fastq.gz", sample = SAMPLES),
    expand("processed_reads/{sample}/.done", sample = SAMPLES),
    expand("cutsequences/{sample}/cutseqs.txt.gz", sample = SAMPLES),
    # GTF,
    # CDSFASTA,
    # expand("rsem/data/{sample}/.done", sample = SAMPLES),
    # expand("fastqc/data/{sample}/.done", sample = SAMPLES),
    # "fastqc/summary/fastqc_summary.tsv",
    expand("star/data/{sample}/.done", sample = SAMPLES),
    # expand("infer_experiment/data/{sample}/.done", sample = SAMPLES),
    # expand("qc/data/{sample}/.done", sample = SAMPLES),
    # expand("dupradar/data/{sample}/.done", sample = SAMPLES),
    # expand("htseq/data/{sample}/.done", sample = SAMPLES),
    expand('feature_counts_readrange/data/{sample}/{generegions}/{readrange}/.done', sample=RIBO_TOTAL_DICT.keys(), generegions=GENEREGIONS+TRNAs, readrange=READRANGES),
    expand("feature_counts/data/{sample}/.done", sample = SAMPLES),
    expand("feature_counts/all_feature_counts"),
    
    # expand("feature_counts/data/{sample}/{generegions}/{readrange}/.done", sample = SAMPLES, generegions = generegions+TRNAs, readrange = READRANGES),
    # expand("kallisto/data/{sample}/.done", sample = SAMPLES),
    # expand("bigwigs/{group}/{strand}/{istrans}.done",group = SAMPLES,strand=strands,istrans=istransvals),
    # expand("mergedbigwigs/{group}/{strand}/{istrans}.done",group = GROUPS,strand=strands,istrans=istransvals),
    # expand("ribotaper/{sample}/.done",sample=list(RIBO_TOTAL_DICT.keys())),
    expand("ribotapermetaplots/{sample}/.done",sample=list(RIBO_TOTAL_DICT.keys())),


MINREADLENGTH=20
MAXREADLENGTH=300
QUALLIM=20
CUTADAPTBIN="~/bin/cutadapt"
REMOVE8NBIN="~/bin/remove8N.pl"

# for sample in $(find gdrive/RiboSeq_Ribo_Transcriptome/ | tail -n +2 |sed 's/.*\///g' | sed 's/.fastq.gz//g' ); do time=$( echo $sample | cut -d'_' -f 1); rep=$(echo $sample | cut -d'_' -f 2) ; sampname=${time}_ribo_$rep; sampfolder=results_2018_02_22/input_preprocessed/$sampname; mkdir -p $sampfolder ; ln -fs  $(readlink -f gdrive/RiboSeq_Ribo_Transcriptome/$sample*) $sampfolder/$sampname.fastq.gz ;done
# for sample in $(find gdrive/RNASeq_Total_Transcriptome/ | tail -n +2 |sed 's/.*\///g' | sed 's/.fastq.gz//g' ); do time=$( echo $sample | cut -d'_' -f 1); rep=$(echo $sample | cut -d'_' -f 2) ; sampname=${time}_total_$rep; sampfolder=results_2018_02_22/input_preprocessed/$sampname; mkdir -p $sampfolder ; ln -fs  $(readlink -f gdrive/RNASeq_Total_Transcriptome/$sample*) $sampfolder/$sampname.fastq.gz ;done

#this is a cludge to put in premade files, in a rush
# for sample in $(find ../gdrive/RiboSeq_Ribo_Transcriptome/ | tail -n +2 |sed 's/.*\///g' | sed 's/.fastq.gz//g' ); do time=$( echo $sample | cut -d'_' -f 1); rep=$(echo $sample | cut -d'_' -f 2) ; sampname=${time}_ribo_$rep;pfile="../processed_reads_ribo/${sample}.uniq.qual20-2xNNNN.fastq.gz"; mkdir -p processed_reads/${sampname}; ln -sf  $(readlink -f $pfile) processed_reads/${sampname}/${sampname}.fastq.gz ; touch processed_reads/${sampname}/.done ;done
# for sample in $(find ../gdrive/RNASeq_Total_Transcriptome/ | tail -n +2 |sed 's/.*\///g' | sed 's/.fastq.gz//g' ); do time=$( echo $sample | cut -d'_' -f 1); rep=$(echo $sample | cut -d'_' -f 2) ; sampname=${time}_total_$rep;pfile="../processed_reads_total/${sample}.uniq.qual20.fastq.gz"; mkdir -p processed_reads/${sampname}; ln -sf  $(readlink -f $pfile) processed_reads/${sampname}/${sampname}.fastq.gz ; touch processed_reads/${sampname}/.done ;done
# ll processed_reads/E13_total_1/*
# zhead processed_reads/E13_total_1/*.fastq.gz


# #also make a little test fastq

#things this needs - cutadapt, remove8N.pl, STAR,collapse_reads.pl,seqtk

rule make_test_fastq:
  input: '../gdrive/RiboSeq_Ribo_Transcriptome','../gdrive/RNASeq_Total_Transcriptome/'
  output: 'preprocessed_reads/test/test.fastq.gz'
  shell:r"""
    set -e
    mkdir -p preprocessed_reads/test/
    seqtk sample -s100 ../gdrive/RNASeq_Total_Transcriptome/E13_1.fastq.gz 10000 | gzip > {output}
    if [ 0 -eq $(gzip -l {output} | awk 'NR==2 {{print $2}}') ]; then rm {output} ; fi

      """

rule link_in_ref:
  input: REF_orig
  output: REF
  shell:r"""
      ln -fs {REF_orig} {REF}
      """

rule link_in_files:
  input: '../gdrive/RiboSeq_Ribo_Transcriptome','../gdrive/RNASeq_Total_Transcriptome/'
  output: 'preprocessed_reads/{sample}/{sample}.fastq.gz'
  run:
    sampnoassay = wildcards['sample']
    sampnoassay = sampnoassay.replace('_ribo','').replace('_total','')
    shell(r"""
      fastq=$(readlink -f ../gdrive/RiboSeq_Ribo_Transcriptome/{sampnoassay}.fastq.gz)
      
      ln -fs $fastq {output}
      ln -fs {REF_orig} {REF}
      """)



rule collapse_reads:
  input: 'preprocessed_reads/{sample}/{sample}.fastq.gz'
  output: touch('collapse_reads/{sample,[^/]+}/.done')
  run:
    sample = wildcards['sample']
    shell(r"""
      set -evx
      
      mkdir -p collapse_reads/{sample}/
      
      zcat {input} \
        | ~/bin/collapse_reads.pl {sample} \
        2> collapse_reads/{sample}/{sample}.collreadstats.txt \
        > collapse_reads/{sample}/{sample}.uniq.fastq
    """)

rule cutadapt_reads:
  input: 'collapse_reads/{sample}/.done'
  output: touch('cutadapt_reads/{sample,[^/]+}/.done')
  run:
    sample = wildcards['sample']
    shell(r"""
      set -evx
      
      mkdir -p cutadapt/{sample}/
      # module load cutadapt;
  
      cutadapt --minimum-length {MINREADLENGTH} \
        --maximum-length {MAXREADLENGTH} \
        -q {QUALLIM} collapse_reads/{sample}/{sample}.uniq.fastq \
        2> cutadapt_reads/{sample}/{sample}.cutadaptstats.txt > \
        cutadapt_reads/{sample}/{sample}.uniq.{MINREADLENGTH}_{MAXREADLENGTH}.qual{QUALLIM}.fastq
    """)

rule trim_reads:
  input: 'cutadapt_reads/{sample}/.done'
  output: touch('processed_reads/{sample,(.*ribo.*)|(test)}/.done')
  run:
    sample = wildcards['sample']
    shell(r"""
      set -evx
      
      mkdir -p processed_reads/{sample}/     
      
      infile="cutadapt_reads/{sample}/{sample}.uniq.{MINREADLENGTH}_{MAXREADLENGTH}.qual{QUALLIM}.fastq"
      trimfile="cutadapt_reads/{sample}/{sample}.uniq.{MINREADLENGTH}_{MAXREADLENGTH}.qual{QUALLIM}-2xNNNN.fastq"
      {REMOVE8NBIN}  $infile

      if [ ! -s $trimfile ] ; then exit; fi
      
      gzip -f $trimfile

      mkdir -p processed_reads/{sample}/
      ln -sf $(readlink -f ${{trimfile}}.gz) processed_reads/{sample}/{sample}.fastq.gz
    # ln -rsf $(readlink -f {input}/*) processed_reads/{sample}/{sample}.fastq.gz
    """)

rule link_total_fastq:
  input: 'preprocessed_reads/{sample}/{sample}.fastq.gz'
  output: touch('processed_reads/{sample,.*total.*}/.done')
  run:
    sample = wildcards['sample']
    shell(r"""
      set -evx
      mkdir -p processed_reads/{sample}/
      ln -sf $(readlink -f {input}) processed_reads/{sample}/{sample}.fastq.gz
    # ln -rsf $(readlink -f {input}/*) processed_reads/{sample}/{sample}.fastq.gz
    """)

KMERSIZE=6


# rule process_reads_total:
#   input: 'preprocessed_reads/{sample}/'
#   output: touch('processed_reads/{sample,.*total.*}/.done')
#   run:
#     sample = wildcards['sample']
#     shell(r"""
#       set -evx
#         ln -rsf $(readlink -f {input}/*) processed_reads/{sample}/{sample}.fastq.gz
#     """)


rule gffread:
  input: REF=REF,GFF_orig=GFF_orig
  output: GTF,CDSGTF,RNAFASTA,CDSFASTA,GFF,BED
  run:
    shell(r"""
      ln -s {input.GFF_orig} {GFF} 
      # set -x
      # module load Cufflinks/2.2.1
      #with filtering, output the coding sequences filteirng out the ones that aren't in frame, have a stop codon, are pseudogenes etc.
      cat {GFF}  \
        | awk -v OFS="\t" '{{if($3=="CDS"){{$3="CDS";print $0}}}}' \
        | sed -r  's/((transcript_id|gene_id|protein_id|ID=\w+|Parent)\W+\w+)\.[0-9]+/\1/g' \
        | gffread - -C -V -J --no-pseudo  -F -E -g {input.REF} \
        -W -w {ANNOBASE}.coding.transcript.fa -x {CDSFASTA} -y {ANNOBASE}.protein.fa -T \
        -o /dev/stdout \
        | awk -v FS="\t" -v OFS="\t" '{{if($3=="CDS"){{$3="exon";print $0}}}}' \
         > {CDSGTF}

      #with filtering output all sequences
      cat {input.GFF_orig}  \
      | awk -v OFS="\t"  '{{if($3=="exon"){{         ;print $0}}}}' \
      | sed -r  's/((transcript_id|gene_id|protein_id|ID=\w+|Parent)\W+\w+)\.[0-9]+/\1/g' \
      | gffread - -F -E -g {input.REF} -W -w {RNAFASTA} -o {GFF_mod}
      #Note we are now minus the transcript and exon entries for these
      #now make GTF
      gffread {GFF_mod} -T -o {GTF}

      #now make bed
      cat {GTF} | awk '{{print $1,$4,$5,"name",$6,$7}}' > {BED}
      """)


# rule make_seqc_gtf:
#   input: GFF_orig
#   output: SeQC_GTF
#   shell: r"""
#         module load Cufflinks/2.2.1
#       cat {GFF_orig} | \
#       grep -v '#' \
#         | awk '$3 ~ "CDS|exon|start_codon|stop_codon|transcript|UTR"'\
#         | sed -r  's/((transcript_id|gene_id|protein_id|ID=\w+|Parent)\W+\w+)\.[0-9]+/\1/g' \
#         | sed 's/geneID/gene_id/'\
#         | grep -P "transcript_type\W+(protein_coding|rRNA)" \
#         | gffread - -T -o {SeQC_GTF} 
#       """
 
rule make_utrs:
  input: GFF=GFF
  output: fputrs='fputrs.gtf',tputrs='tputrs.gtf'
  # script: 'make_utrfiles.R'
  run:
    shell(r"""
      set -ex
      # module load Cufflinks/2.2.1
      #with filtering output all sequences
      cat {input.GFF}  \
      | awk -v OFS="\t"  '{{if($3=="five_prime_UTR"){{         ;print $0}}}}' \
      | sed -r  's/((transcript_id|gene_id|protein_id|ID=\w+|Parent)\W+\w+)\.[0-9]+/\1/g' \
      | gffread - -T -o {output.fputrs} 

      cat {input.GFF} \
      | awk -v OFS="\t"  '{{if($3=="three_prime_UTR"){{         ;print $0}}}}' \
      | sed -r  's/((transcript_id|gene_id|protein_id|ID=\w+|Parent)\W+\w+)\.[0-9]+/\1/g' \
      | gffread - -T -o {output.tputrs}

     
      """) 
rule fastqc:
     input: 
          'processed_reads/{sample}/.done'
     output: 
          done = touch('fastqc/data/{sample}/.done')
     run:
          read_pattern = READ_PATTERN_DICT[wildcards['sample']]
          shell(r"""
          set -e
          mkdir -p fastqc/reports/{wildcards.sample} 
          {SCRIPTDIR}/run_my_fastqc.sh -i $(dirname {input}) {read_pattern} -o $(dirname {output.done}) -@ 2 \
          &> fastqc/reports/{wildcards.sample}/{wildcards.sample}.fastqc.log
          """)

rule collect_fastqc:
     input:
          all_results = expand("fastqc/data/{sample}/.done", sample=SAMPLES)
     output:
          result='fastqc/summary/fastqc_summary.tsv',
          log='fastqc/summary/fastqc_summary.log'
     shell:
          r"""
          set -e
          mkdir -p $(dirname {output.result}) 
          {SCRIPTDIR}/collect_fastqc_results.sh -i fastqc/ \
          > {output.result} \
          2> {output.log} 
          """

rule star:
     input:
          fastqs='processed_reads/{sample}/.done',
          STARINDEX=STARINDEX,
     output:
          done = touch('star/data/{sample,[^/]+}/.done')
     threads: 8
     run:
          read_pattern = READ_PATTERN_DICT[wildcards['sample']]
          shell(r"""
          
          mkdir -p star/reports/{wildcards.sample}
          {SCRIPTDIR}/run_my_star.sh -m -@ {threads} -i $(dirname {input.fastqs}) {read_pattern} -o $(dirname {output}) \
          -r star/reports/{wildcards.sample} -t {TMPDIR} -l NoSharedMemory -x {STARINDEX} 
          """)
rule cutsite_kmers:
  input: 'star/data/{sample}/{sample}.bam',REF
  output: 'cutsequences/{sample}/cutseqs.txt.gz'
  threads: 8
  run:

    chromsizes = 'cutsequences/'+wildcards['sample']+'/chrsizes'
    halfKMERSIZE = KMERSIZE/2
    shell(r"""
        set -evx
        samtools view -H {input} | grep "SQ" | sed -r 's/^@SQ\s+SN://' | sed -r "s/\s+LN:/\t/" > {chromsizes} 
        mkdir -p cutsequences/{wildcards.sample}

        samtools view -bF 0x10 {input[0]} \
          | bedtools bamtobed -i stdin | head -n 100000 \
          | bedtools intersect -a /dev/stdin -b {CDSGTF} -u \
          | awk -v OFS="\t" '{{print $1,$2-{halfKMERSIZE},$2+{halfKMERSIZE}}}' \
          | bedtools getfasta -bed - -fi {REF} -fo /dev/stdout -s \
          | grep -v ">"  | sort | uniq -c  | gzip > {output}
       

        samtools view -bF 0x10 {input[0]} \
          | bedtools bamtobed -i stdin | head -n 100000 \
          | bedtools intersect -a /dev/stdin -b {CDSGTF} -u \
          | awk -v OFS="\t" '{{print $1,$3-{halfKMERSIZE},$3+{halfKMERSIZE}}}' \
          |bedtools getfasta -bed - -fi {REF} -fo /dev/stdout -s \
          | grep -v ">"  | sort | uniq -c  | gzip > {output}.right.gz

          # |bedtools slop -i - -b -{halfKMERSIZE} -g {chromsizes}  \
          # |bedtools flank -b {KMERSIZE} -i /dev/stdin -g {chromsizes} \
          # | awk 'NR%2==0' 

        # bedtools bamtobed -i {input[0]} \
        #   |grep '+$' \
        #   |bedtools intersect -a /dev/stdin -b {CDSGTF} -u \
        #   |bedtools slop -i - -b -{halfKMERSIZE} -g {chromsizes}  \
        #   |bedtools flank -b {KMERSIZE} -i /dev/stdin -g {chromsizes} \
        #   |awk 'NR%2==1'  \
        #   |bedtools getfasta -bed /dev/stdin -fi {REF} -fo /dev/stdout -s \
        #   | grep -v ">"  | sort | uniq -c  | gzip > {output}.right.gz
  """)



# TESTSECTION="1:1-1260071"

# rule preprocess_bam:
#     input: get_bam
#     output: "work/{sample}/{sample}.preprocess.bam"
#     shell: r"""
#     samtools view -bh {input} {TESTSECTION} > {output}
#     samtools index {output}
#     """


# rule bwa_mem:
#      input:
#           'processed_reads/{sample}/{sample}.fastq.gz'
#      output:
#           done = touch('star/data/{sample}/.done')
#      threads: 8
#      run:
#           read_pattern = READ_PATTERN_DICT[wildcards['sample']]
#           shell(r"""
#           set -e
#           mkdir -p star/reports/{wildcards.sample}
#           {SCRIPTDIR}/run_my_star.sh -m -@ {threads} -i {input} {read_pattern} -o $(dirname {output}) \
#           -r star/reports/{wildcards.sample} -t {TMPDIR} -l NoSharedMemory -x {STARINDEX} 
#           """)

def get_trackfile(sample,strand,ext):
  return 'bigwigs/'+sample+'/'+strand+'/'+sample+'.'+strand+ext

#TODO strand is a problem here
rule bigwigs:
     input: 
          "star/data/{sample}/.done"
     output:
          done = touch("bigwigs/{sample}/{strand}/{istrans}.done")
     threads: 1
     run:
        bedgraph = get_trackfile(wildcards.sample,wildcards.strand,wildcards.istrans+'.bg')
        bw = get_trackfile(wildcards.sample,wildcards.strand,wildcards.istrans+'.bw')
        bext = BEXTS[wildcards.istrans]
        bam = 'star/data/'+wildcards.sample+'/'+wildcards.sample+bext+'.bam'        
        chromsizes = 'bigwigs/'+wildcards.sample+'/'+wildcards.istrans+'.chrsizes.txt'
        strandsym = STRANDSYMS[wildcards.strand]
        #turns out reversing the y axis breaks bigwig merge....
        # revyaxis = -1 if strandsym is '-' else 1
        revyaxis = 1

        shell(r"""
        set -e
        module purge
        module load BEDTools/2.24.0-foss-2015a
        module load kenttools/v329-foss-2015a
        module load SAMtools/1.3.1-foss-2015a
        mkdir -p bigwigs/{wildcards.sample}/{wildcards.strand}
       
        # count="$(cat star/reports/{wildcards.sample}/{wildcards.sample}.bam.bamstats.txt | \
        #  grep -Po "reads mapped:\s+\d+" | \
        #  grep -Po "\d+$" | awk '{{print {revyaxis}*1000000/$0}}' 
        #  )"
        count=1
        samtools view -H {bam} | grep "SQ" | sed -r 's/^@SQ\s+SN://' | sed -r "s/\s+LN:/\t/" > {chromsizes} 

        bedtools genomecov -ibam {bam} -bg -strand {strandsym} -split -scale $count > {bedgraph}
        bedSort {bedgraph} {bedgraph}
        bedGraphToBigWig {bedgraph} {chromsizes} {bw}
       
        """)


def getGroupBigWigs(wildcards):
    strand = wildcards['strand']
    samples = GROUP_SAMPLES[wildcards['group']]
    return [get_trackfile(s,strand,wildcards.istrans+'.bw') for s in samples ]


def getGroupBigWigDone(wildcards):
    strand = wildcards['strand']
    samples = GROUP_SAMPLES[wildcards['group']]
    return ['bigwigs/'+s+'/'+strand+'/'+wildcards.istrans+'.done' for s in samples ]


rule mergedbigwigs:
     input: getGroupBigWigDone
     output:
          done = touch('mergedbigwigs/{group}/{strand}/{istrans}.done')
     threads: 1
     run:
        chromsizes = 'bigwigs/'+GROUP_SAMPLES[wildcards.group][0]+'/'+wildcards.istrans+'.chrsizes.txt' 
        bigwigs = getGroupBigWigs(wildcards)
        libnum = len(bigwigs)
        mergedfilebase="mergedbigwigs/"+wildcards.group+"/"+wildcards.strand+"/"+wildcards.group+"."+wildcards.strand+wildcards.istrans


        shell(r"""
        set -xe
        module purge
        module load kenttools/v329-foss-2015a
        mkdir -p mergedbigwigs/{wildcards.group}/{wildcards.strand}/
        
        bigWigMerge {bigwigs} /dev/stdout | awk 'BEGIN{{OFS="\t"}}{{$4 = $4 /{libnum} ; print $0 }}' > {mergedfilebase}.bg 
        
        bedSort {mergedfilebase}.bg {mergedfilebase}.bg 

        bedGraphToBigWig \
          {mergedfilebase}.bg \
          {chromsizes} \
          {mergedfilebase}.bw

        rm {mergedfilebase}.bg
        """)
# set -e  pipefail; 
#         set -xe
#         module purge
#         module load kenttools/v329-foss-2015a
#         mkdir -p mergedbigwigs/E175_ribo/pos/
        
#         bigWigMerge bigwigs/E175_ribo_1/pos/E175_ribo_1.pos.chr.bw bigwigs/E175_ribo_2/pos/E175_ribo_2.pos.chr.bw /dev/stdout | awk '{$4 = $4 /2  }' > mergedbigwigs/E175_ribo/pos/E175_ribo.pos.chr.bg 
        
#         bedSort mergedbigwigs/E175_ribo/pos/E175_ribo.pos.chr.bg mergedbigwigs/E175_ribo/pos/E175_rib
# o.pos.chr.bg 

#         bedGraphToBigWig \
#           mergedbigwigs/E175_ribo/pos/E175_ribo.pos.chr.bg \
#           bigwigs/E175_ribo_1/.chr.chrsizes.txt \
#           mergedbigwigs/E175_ribo/pos/E175_ribo.pos.chr.bw

#         rm mergedbigwigs/E175_ribo/pos/E175_ribo.pos.chr.bg
rule infer_experiment:
     input:
          'star/data/{sample}/.done'
     output:
          done = touch('infer_experiment/data/{sample}/.done')
     shell:
          r"""
          set -e
          mkdir -p infer_experiment/data/{wildcards.sample}
          
          module purge
          module load RSeQC/2.6.2-foss-2015a-Python-2.7.9
          infer_experiment.py -r {BED} \
          -i star/data/{wildcards.sample}/{wildcards.sample}.bam \
          -q 255 > infer_experiment/data/{wildcards.sample}/{wildcards.sample}.strand_stat.txt
          """
     

rule htseq:
     input:
          'star/data/{sample}/.done',GTF
     output:
          done = touch('htseq/data/{sample}/.done')
     run:
          protocol = PROTOCOL_DICT[wildcards['sample']]
          GTF = GTF_DICT[wildcards['sample']]
          shell(r"""
          set -e
          mkdir -p htseq/reports/{wildcards.sample}
          {SCRIPTDIR}/run_my_htseq-count.sh \
          -b star/data/{wildcards.sample}/{wildcards.sample}.bam \
          -o $(dirname {output}) -g {GTF} \
          -m {HTSEQ_MODE} -s {protocol} -r pos &> htseq/reports/{wildcards.sample}/{wildcards.sample}.htseq.log
          """)


# rule make_salmon_index:
#   threads: 8
#   run:
#     shell(""" salmon index -p 8 --perfectHash -k {KMERSIZE} -t {RNAFASTA} -i salmonindex""")

# rule salmon:
#   input:
#     'star/data/{sample}/.done'
#      output:
#       done = touch('salmon/data/{sample}/.done')
#      threads: 8
#      GTF = GTF_DICT[wildcards['sample']]
#           protocol = PROTOCOL_DICT[wildcards['sample']]
#           if (protocol == 'no'):
#                protocol = 0
#           elif (protocol == 'yes'):
#                protocol = 1
#           elif (protocol == 'reverse'):
#                protocol = 2
#           else:
#                sys.exit('Protocol not known!')

#            library = LIBRARY_DICT[wildcards['sample']]

#           if (library == 'PAIRED'):
#             if protocol == ''
#                FORMATSTRING = 'I'
#           else:
#                library = ''

#           TARGETFASTA

#           FORMATSTRING = format1+format2+format3

#           shell(r"""
#           set -ex
#           mkdir -p salmon/reports/{wildcards.sample}
#           mkdir -p salmon/data/{wildcards.sample}
#       salmon quant \
#       -l {FORMATSTRING} \
#       --seqBias --gcBias \
#       -g transcript_gene_map.tsv \
#       -t {TARGETFASTA} \
#       --fldMean 433 --fldSD 186 -a star/data/E13_total_1/E13_total_1.star_transcript.bam --output salmon/data/E13_total_1/E13_total_1

#           {SCRIPTDIRsalmon -m -@ {threads} -i {input} {read_pattern} -o $(dirname {output}) \
#           -r star/reports/{wildcards.sample} -t {TMPDIR} -l NoSharedMemory -x {STARINDEX} 
#           """)


 

rule rsem:
     input:
          'star/data/{sample}/.done',
          RSEMINDEXFOLD+'/.done'
     output:
          done = touch('rsem/data/{sample}/.done')
     threads: 8
     run:
        frag_length_mean = FRAG_LENGTH_MEAN_DICT[wildcards['sample']]
        indexname = RSEMINDEXFOLD+'/'+(os.path.basename(GTF).replace('.gtf',''))

        frag_length_sd = FRAG_LENGTH_SD_DICT[wildcards['sample']]

        shell(r"""
        set -e

        rm -rf $(dirname {output})
        mkdir -p $(dirname {output})
        rm -rf rsem/reports/{wildcards.sample}
        mkdir -p rsem/reports/{wildcards.sample}


        {SCRIPTDIR}/run_my_rsem.sh -@ {threads} \
        -b star/data/{wildcards.sample}/{wildcards.sample}.star_transcript.bam \
        -o $(dirname {output}) -r rsem/reports/{wildcards.sample} -t {TMPDIR} \
        -x $(echo {RSEMINDEXFOLD}/*grp | sed s/.grp//) \
        -f {frag_length_mean} -d {frag_length_sd} \
        # &> rsem/reports/{wildcards.sample}/{wildcards.sample}.rsem.log
        """)


rule qc:
     input:
          SeQC_GTF=SeQC_GTF,
          fastqc='fastqc/data/{sample}/.done',
          star='star/data/{sample}/.done',
          SeQC_REF_fai = SeQC_REF+".fai"
     output:
          done=touch('qc/data/{sample}/.done'),
          metrics='qc/data/{sample}/RNA-SeQC/metrics.tsv'
     shell:
          r"""
          set -e
          set -xv
          
          mkdir -p qc/reports/{wildcards.sample}
          {SCRIPTDIR}/run_my_qc.sh -e \
            -l star/reports/{wildcards.sample}/Log.final.out -f $(dirname {input.fastqc}) \
            -b star/data/{wildcards.sample}/{wildcards.sample}.bam -g {input.SeQC_GTF} -r {SeQC_REF} -o $(dirname {output}) \
            &> qc/reports/{wildcards.sample}/{wildcards.sample}_qc.log
          
          """
     
     
rule dupradar:
    input:
        'star/data/{sample}/.done'
    output:
        touch('dupradar/data/{sample}/.done')
    run:
        library = LIBRARY_DICT[wildcards['sample']]
        paired = 'TRUE' if library == 'PAIRED' else 'FALSE'

        protocol = PROTOCOL_DICT[wildcards['sample']]
        map_protocol = { 'no': 0, 'yes': 1, 'reverse': 2 }
        stranded = map_protocol[protocol]

        shell(r"""
        module unuse /fast/projects/cubit/current/tools/easybuild/modules/all
        module use /fast/projects/cubit/wip_oliver/tools/easybuild/modules/all
        module purge
        module load dupRadar/1.4.0-foss-2015a-R-3.2.4

        outdir=$(dirname {output})
        id={wildcards.sample}
        bam=$(dirname {input})/${{id}}.bam
        threads=8

        mkdir -p $outdir
        
        Rscript --vanilla {SCRIPTDIR}/dupradar.R \
            $bam \
            $id \
            {GTF} \
            {stranded} \
            {paired} \
            $threads \
            $outdir
        """)


rule make_kallisto_index:
  input: 
    RNAFASTA,
    CDSFASTA
  output: KINDEX,KINDEXCDS,'sizes.genome'
  shell:
    r"""
    set -ex
    export LD_LIBRARY_PATH=/fast/users/harnettd_c/miniconda3/lib/:$LD_LIBRARY_PATH 
    mkdir -p kallistoindex

    samtools faidx {REF}
    cut -f1,2 {REF}.fai > sizes.genome

    {kallistobin} index -i {KINDEXCDS} -k {KMERSIZE} {RNAFASTA}
    {kallistobin} index -i {KINDEX}  -k {KMERSIZE} {CDSFASTA}
    """

    
    
rule kallisto:
  input:
    'processed_reads/{sample}/.done',
    KINDEX,
    KINDEXCDS,
    'sizes.genome'
  output:
    done = touch('kallisto/data/{sample}/.done')
  threads: 8
  run:
    frag_length_mean = FRAG_LENGTH_MEAN_DICT[wildcards['sample']]
    frag_length_sd = FRAG_LENGTH_SD_DICT[wildcards['sample']]
    read_pattern = READ_PATTERN_DICT[wildcards['sample']]
    kallistoindex = KINDEXDICT[wildcards['sample']]
    protocol = PROTOCOL_DICT[wildcards['sample']]


    if (protocol == 'no'): protocol = ''
    elif (protocol == 'yes'):
      protocol = '--fr-stranded'
    elif (protocol == 'reverse'):
      protocol = '--rf-stranded'
    else:
      sys.exit('Protocol not known!')
    fastqfold = input[0].replace('.done','')

    shell(r"""
    set -ex
    rm -rf kallisto/*/{wildcards.sample}/
    mkdir -p kallisto/reports/{wildcards.sample}

    export LD_LIBRARY_PATH=$HOME/miniconda3/lib/:$LD_LIBRARY_PATH 

    {SCRIPTDIR}/run_my_kallisto.sh  -x {kallistoindex} -c \
    -@ {threads} \
    -s {protocol} \
    -b 1 \
    -t {TMPDIR} -i {fastqfold} {read_pattern} \
    -l {frag_length_mean} -d {frag_length_sd} \
     -o $(dirname {output}) 
    """)
    # -p  \
    # -m sizes.genome \
    # -a \
    # -g {GTF}\


RIBOTAPERDIR="$HOME/Applications/ribotaper-1.3.1a/scripts/"
RIBOTAPERANNOTDIR="Ribotaper_annot"

rule make_ribotaper_annot:
  input: GTF_orig = '/fast/projects/cubit/0.12.0/static_data/annotation/GENCODE/M12/GRCm38/gencode.vM12.annotation.gtf'
  output: touch(RIBOTAPERANNOTDIR+"/.done")
  run:
    shell(r"""
      set -ex

      mkdir -p {RIBOTAPERANNOTDIR}
      {RIBOTAPERDIR}/create_annotations_files.bash $(readlink -f {input.GTF_orig}) $(readlink -f {REF}) 'false' 'false' {RIBOTAPERANNOTDIR}
      """)

rule make_ribotaper_metaplots:
  input:
    annodir = RIBOTAPERANNOTDIR+"/.done",
    ribobam = "star/data/{sample}/{sample}.bam"
  output:
    touch('ribotapermetaplots/{sample}/.done')
  run:
    startstopbed=RIBOTAPERANNOTDIR+'/start_stops_FAR.bed'
    shell(r"""
      mkdir -p ribotapermetaplots/{wildcards.sample}
      bed=$(readlink -f {startstopbed})
      bam=$(readlink -f {input.ribobam})
      cd ribotapermetaplots/{wildcards.sample}
      rm -rf metaplots
      {RIBOTAPERDIR}/create_metaplots.bash $bam $bed {wildcards.sample}
      """)


skribo_rnafold = 'skribo_rnafold'
rnafoldbin = '/fast/users/harnettd_c/Applications/scikit-ribo/scikit_ribo/'
skindexfold = 'skribo_index'
rule scikit_rnafold:
  input: RNAFASTA,
  output: skribo_rnafold
  run:
    shell(r"""
      set -xv
    python {rnafoldbin}//call_rnafold.py\
    -f shortname_my_gencode.vM12.annotation.transcript.fa \
    -r {rnafoldbin} \
    -p testskribo \
    -o {skribo_rnafold} 
    """)

    # gtf=<gtf-file-location>
    # fasta=<ref-genome-fasta-location>
    # bam=<bam-file-location> # from STAR
    # rnafold=<path to the Rnafold file> # the file generated by call_rnafold.py
    # prefix=<prefix-to-use> # defined by user
    # index_folder=<index-output-folder>
    # RNA=<RNAseq-TPM-file-location> # gene level TPM generated with salmon or kallisto
    # output=<output-folder>
    # unmap=<unmap-regions>
#-g {GTF_orig} \

rule scikit_ribo_build:
  input: skribo_rnafold
  output: touch('skindexfold/{sample}/.done')
  run:
    shell(r"""

    mkdir -p {skindexfold}/{wildcards.sample}
    scikit-ribo-build.py \
    -g test.gtf \
    -f {REF} \
    -p testskribo \
    -r {skribo_rnafold} \
    -t kallisto/data/{wildcards.sample}/out.d/abundance.tsv\
    -o {skindexfold}/{wildcards.sample}
""")


rule scikit_ribo:
  input: 'skindexfold/{sample}/.done'
  output: touch('scikitribo/{sample}/.done')
  run:
    shell(r"""

    scikit-ribo-run.py \
    -i star/data/{wildcards.sample}/{wildcards.sample}.bam \
    -f {skindexfold} \
    -p testskribo \
    -o scikitribo/{wildcards.sample}/ """)


#this is going to count reads in each library over 5'UTRS, CDS, and 3' UTRs


# rule feature_counts:
#      input:
#           'star/data/{sample}/.done',GTF,CDSGTF,'tputrs.gtf','fputrs.gtf'
#      output:
#           done = touch('feature_counts/data/{sample,[^/]+}/.done')
#      threads: 2
#      run:
#           GTF = GTF_DICT[wildcards['sample']]
#           protocol = PROTOCOL_DICT[wildcards['sample']]
#           if (protocol == 'no'):
#                protocol = 0
#           elif (protocol == 'yes'):
#                protocol = 1
#           elif (protocol == 'reverse'):
#                protocol = 2
#           else:
#                sys.exit('Protocol not known!')

#           library = LIBRARY_DICT[wildcards['sample']]

#           if (library == 'PAIRED'):
#                library = '-p'
#           else:
#                library = ''

#           shell(r"""
#           set -e
#           module purge
#           module load subread/1.4.6-p5

#           mkdir -p feature_counts/reports/{wildcards.sample}
#           mkdir -p feature_counts/data/{wildcards.sample}

#           featureCounts \
#           -T {threads} \
#           -t exon -gg ene_id \
#           -a {GTF} \
#           -s {protocol} {library} \
#           -o feature_counts/data/{wildcards.sample}/{wildcards.sample}.feature_counts \
#           star/data/{wildcards.sample}/{wildcards.sample}.bam \
#           &> feature_counts/reports/{wildcards.sample}/{wildcards.sample}.feature_counts.log
#           """)


rule readlenfilt:
  input: 'star/data/{sample}/.done'
  output:  'readlenfilt/data/{sample}/{readrange}/readlenfilt.bam'
  run:
    minreadlen,maxreadlen = READRANGEDICT[wildcards['readrange']]

    readrangebam = output[0]
    shell(r"""
          set -ex
          samtools view -h $(dirname {input})/{wildcards.sample}.bam \
           | awk '((length($10) >= {minreadlen})&&(length($10) <= {maxreadlen})) || $1 ~ /^@/' \
          | samtools view -S -b - > {readrangebam}
            
      """)

rule feature_counts_readrange:
     input:
          GTF,CDSGTF,'tputrs.gtf','fputrs.gtf','tRNAs.gtf',
          readrangefilt='readlenfilt/data/{sample}/{readrange}/readlenfilt.bam'

     output:
          done = touch('feature_counts_readrange/data/{sample,[^/]+}/{generegions}/{readrange}/.done')
     threads: 2
     log: r"""feature_counts_readrange/reports/{sample}/{generegions}/{readrange}/feature_counts.log"""
     run:
          if (wildcards['generegions'] in ['gene','cds']):
            GTF = GTF_DICT[wildcards['sample']]
            groupcol = 'gene_id'
          else:
            GTF = wildcards['generegions']+'.gtf'
            groupcol = 'transcript_id'
          
          protocol = PROTOCOL_DICT[wildcards['sample']]
          if (protocol == 'no'):
               protocol = 0
          elif (protocol == 'yes'):
               protocol = 1
          elif (protocol == 'reverse'):
               protocol = 2
          else:
               sys.exit('Protocol not known!')

          library = LIBRARY_DICT[wildcards['sample']]

          if (library == 'PAIRED'):
               library = '-p'
          else:
               library = ''

          countmultimappers = ' ' 
          
          if (wildcards['generegions']=='tRNAs'):
            featuretype = 'tRNA'
            countmultimappers = '-M --fraction'
          
          elif  (wildcards['generegions']=='tputrs'):
            featuretype = 'exon'
          elif  (wildcards['generegions']=='fputrs'):
            featuretype = 'exon'
          else:
            featuretype = 'exon'


          sample = wildcards['sample']
          generegions = wildcards['generegions']
          readrange = wildcards['readrange']
          rangebam = input['readrangefilt']
          
          shell(r"""
          set -e
          module purge
          module load subread/1.4.6-p5

          mkdir -p feature_counts_readrange/reports/{sample}
          mkdir -p feature_counts_readrange/data/{sample}


          featureCounts \
            -T {threads} \
            -t {featuretype} -g {groupcol} \
            -a {GTF} \
            -s {protocol} {library} \
            -o feature_counts_readrange/data/{sample}/{generegions}/{readrange}/feature_counts \
            {countmultimappers} \
            {rangebam}

          """)

rule feature_counts:
     input:
          'star/data/{sample}/.done',GTF,CDSGTF,'tputrs.gtf','fputrs.gtf',
          expand('feature_counts_readrange/data/{sample}/{generegions}/{readrange}/.done', sample=RIBO_TOTAL_DICT.keys(), generegions=GENEREGIONS+TRNAs, readrange=READRANGES),
          expand('feature_counts_readrange/data/{sample}/{generegions}/{readrange}/.done', sample=RIBO_TOTAL_DICT.values(), generegions=GENEREGIONS+TRNAs, readrange=READRANGES[-1]),
     output:
          done = touch('feature_counts/data/{sample,[^/]+}/.done')
     threads: 2
     run:       
        bamfile = 'star/data/'+wildcards['sample']+'/'+wildcards['sample']+'.bam' 
        if 'ribo' in wildcards['sample']:
          selregion='cds'
          selreadrange='25_30'
        else:
          selregion='cds'
          selreadrange='1_300'
        shell(r"""

          mkdir -p feature_counts/reports/{wildcards.sample}
          mkdir -p feature_counts/data/{wildcards.sample}

          head -n2 feature_counts_readrange/data/{wildcards.sample}/{selregion}/{selreadrange}/feature_counts \
          | tail -n1 \
          | awk '{{$7= "{bamfile}"}}' \
          >    feature_counts/data/{wildcards.sample}/{wildcards.sample}.feature_counts

          tail -n+3 feature_counts_readrange/data/{wildcards.sample}/{selregion}/{selreadrange}/feature_counts \
          >    feature_counts/data/{wildcards.sample}/{wildcards.sample}.feature_counts
          """)

rule aggregate_feature_counts:
  input : expand("feature_counts/data/{sample}/.done", sample = SAMPLES),
  output: 'feature_counts/all_feature_counts'
  run:
    fcountfiles = expand("feature_counts/data/{sample}/{sample}.feature_counts", sample = SAMPLES)
    shell(r""" 

       #( (sed '2q;d' {fcountfiles[0]} | cut -f1,7 && tail -n+3 {fcountfiles[0]}| sort -k1 | cut -f1,7) > {output})
       tail -n+3 {fcountfiles[0]}| sort -k1 | cut -f1,7 > {output}
       
       #now for eahc fcount table, join it to the ids
       for fcountfile in $(echo {fcountfiles}); do

          tail -n+3 $fcountfile| sort -k1 | cut -f1,7 | join {output} - | sort -k1 > {output}tmp
          mv {output}tmp {output}
       
       done

      echo "feature_id {SAMPLES}" | cat - {output} > {output}tmp
      mv {output}tmp {output}
    
      """)

# ule feature_counts_select:
#      input:
#           GTF,CDSGTF,'tputrs.gtf','fputrs.gtf','tRNAs.gtf',
#           readrangefilt='readlenfilt/data/{sample}/{readrange}/readlenfilt.bam'

#      output:
#           done = touch('feature_counts/data/{sample,[^/]+}/{generegions}/{readrange}/.done')
#      threads: 2
#      log: r"""feature_counts/reports/{sample}/{generegions}/{readrange}/feature_counts.log"""
#      run:
#           if (wildcards['generegions'] in ['gene','cds']):
#             GTF = GTF_DICT[wildcards['sample']]
#             groupcol = 'gene_id'
#           else:
#             GTF = wildcards['generegions']+'.gtf'
#             groupcol = 'transcript_id'
          
#           protocol = PROTOCOL_DICT[wildcards['sample']]
#           if (protocol == 'no'):
#                protocol = 0
#           elif (protocol == 'yes'):
#                protocol = 1
#           elif (protocol == 'reverse'):
#                protocol = 2
#           else:
#                sys.exit('Protocol not known!')

#           library = LIBRARY_DICT[wildcards['sample']]

#           if (library == 'PAIRED'):
#                library = '-p'
#           else:
#                library = ''

#           if (wildcards['generegions']=='tRNAs'):
#             featuretype = 'tRNA'
#           elif  (wildcards['generegions']=='tputrs'):
#             featuretype = 'exon'
#           elif  (wildcards['generegions']=='fputrs'):
#             featuretype = 'exon'
#           else:
#             featuretype = 'exon'


#           sample = wildcards['sample']
#           generegions = wildcards['generegions']
#           readrange = wildcards['readrange']
#           rangebam = input['readrangefilt']

#           shell(r"""
            
#           """)
# #this is going to count reads in each library over 5'UTRS, CDS, and 3' UTRs
# rule aggregate_feature_counts:
#      input:
#           'star/data/{sample}/.done',GTF,CDSGTF
#      output:
#           expand('feature_counts/data/{sample}/{generegions}.done',sample=SAMPLES)
#      threads: 2
#      log: r"""feature_counts/reports/{wildcards.sample}/{wildcards.sample}.{generegions}feature_counts.log"""
#      run:
#           if (wildcards['generegions']=='gene'):
#             GTF = GTF_DICT[wildcards['sample']]
#           else:
#             GTF = wildcards['generegions']+'.gtf'
#           protocol = PROTOCOL_DICT[wildcards['sample']]
#           if (protocol == 'no'):
#                protocol = 0
#           elif (protocol == 'yes'):
#                protocol = 1
#           elif (protocol == 'reverse'):
#                protocol = 2
#           else:
#                sys.exit('Protocol not known!')

#           library = LIBRARY_DICT[wildcards['sample']]

#           if (library == 'PAIRED'):
#                library = '-p'
#           else:
#                library = ''

#           shell(r"""
#           set -e
#           module purge
#           module load subread/1.4.6-p5

#           mkdir -p feature_counts/reports/{wildcards.sample}
#           mkdir -p feature_counts/data/{wildcards.sample}

#           featureCounts \
#           -T {threads} \
#           -t exon -g gene_id \
#           -a {GTF} \
#           -s {protocol} {library} \
#           -o feature_counts/data/{wildcards.sample}/{wildcards.sample}.{wildcards.generegions}feature_counts \
#           star/data/{wildcards.sample}/{wildcards.sample}.bam
#           """)
